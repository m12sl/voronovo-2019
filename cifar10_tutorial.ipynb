{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Перевод туториала](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) с небольшими добавлениями.\n",
    "\n",
    "В этой тетрадке мы натренируем небольшую сверточную сеть для классификации картинок из датасета Cifar-10.\n",
    "Цель познакомить с основными шагами тренировки:\n",
    "\n",
    "1. Описать генератор данных\n",
    "2. Написать нейронную сеть\n",
    "3. Задать функцию ошибки\n",
    "4. Написать тренировочный цикл\n",
    "5. Натренировать модель\n",
    "6. Попробовать применить.\n",
    "\n",
    "\n",
    "В данном случае код для загрузки данных на train/validation уже написан за нас и находится в `torchvision.datasets`.\n",
    "\n",
    "Обычно нам требуется три компоненты:\n",
    "\n",
    "1. **Dataset** наследуется от `torch.utils.data.Dataset`.\n",
    "\n",
    "    В классе должно быть реализовано два метода:\n",
    "\n",
    "    - `__getitem__(self, item)`, он возвращает семпл (в данном случае картинку и номер класса для нее)\n",
    "    - `__len__(self)`, количество примеров в датасете.\n",
    "\n",
    "2. **DataLoader** часто используется готовый `torch.utils.data.DataLoader`.\n",
    "\n",
    "    Принимает на вход `dataset`, размер батча и дополнительные параметры.\n",
    "    Внутри вызывает `dataset.__getitem__` нужное количество раз и складывает семплы в батч.\n",
    "\n",
    "3. **transform** -- функция для предобработки картинок, обычно подается в Dataset при инициализации. Полезна для аугментаций и получения более подходящих представлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar10\n",
    "\n",
    "Состоит из цветных картинок 32х32, содержит 10 классов:\n",
    "‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
    "\n",
    "Картинки в нем по умолчанию представлены в виде массивов пикселей со значениями от 0 до 1. При загрузке мы перевели их в интервал $(-1, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пишем сверточную сеть.\n",
    "\n",
    "В pytorch принят **channels-first** порядок осей. \n",
    "Это означает, что в сеть приходят тензоры с размерами `[batch_size, channels, width, height]`. \n",
    "\n",
    "\n",
    "Сверточные сети обычно собираются из последовательности слоев:\n",
    "\n",
    "### Convolution\n",
    "https://pytorch.org/docs/stable/nn.html#convolution-layers\n",
    "\n",
    "По тензору бежит скользящее окно и в нем вычисляется свертка с ядром.\n",
    "Обычно говорят о пространственных размерах сверток, например 1x1 или 3x3  свертки, подразумевая, что ядра имеют размер `[1,1,ch]` или `[3,3,ch]`.\n",
    "\n",
    "Сейчас часто используются чуть более сложные варианты сверток: \n",
    "- dilated (atrous, дырявые), \n",
    "- depth-wise\n",
    "- pointwise\n",
    "- separable\n",
    "- group\n",
    "\n",
    "\n",
    "### Pooling\n",
    "https://pytorch.org/docs/stable/nn.html#pooling-layers\n",
    "\n",
    "Действуют аналогично свертках, но не имеют весов, а в бегущем окне вычисляется какая-нибудь функция, например max или mean.\n",
    "\n",
    "\n",
    "### Global pooling (Adaptive Pooling)\n",
    "https://pytorch.org/docs/stable/nn.html#adaptivemaxpool1d\n",
    "\n",
    "Глобальные пулинги (в pytorch они называются adaptive) убирают пространственные размерности, превращая `[bs, ch, h, w]` в `[bs, ch, 1, 1]`.\n",
    "\n",
    "\n",
    "\n",
    "Удобно выделять в сверточных сетях две части: полносверточную (body, feature extractor, тушка) и классификатор (head, голова).\n",
    "\n",
    "Классификатор обычно состоит из полносвязных слоев (и где-то может обозначаться как MLP, MLP-head), и требует фиксированного размера тензоров (batch_size может варьироваться, но остальные размерности фиксированы).\n",
    "\n",
    "Полносверточная часть обычно может работать на входах произвольных размеров (не меньше минимального).\n",
    "\n",
    "\n",
    "Чтобы объединить эти две части используют какую-нибудь из операций: **Flatten** или **Global Pooling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# check network consistency\n",
    "print(net(torch.zeros([32, 3, 32, 32])).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ошибки и оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # объединяет LogSoftmax и NLL\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нарисуем вычислительный граф для бекпропа\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "out = net(images)\n",
    "loss = criterion(net(images), labels)\n",
    "make_dot(loss, params=dict(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для отображения прогресса нам потребуются дополнительные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Some auxilary function for plots\n",
    "def plot_history(log, name=None):\n",
    "    \"\"\"log is list of dictionaries like \n",
    "        [\n",
    "            {'train_step': 0, 'train_loss': 10.0, 'train_acc': 0.0}, \n",
    "            ...\n",
    "            {'train_step': 100, 'val_loss': 0.1, 'val_acc': 0.9},\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        name='loss'\n",
    "    train_points, val_points = [], []\n",
    "    train_key = 'train_{}'.format(name)\n",
    "    val_key = 'val_{}'.format(name)\n",
    "\n",
    "    for entry in log:\n",
    "        if train_key in entry:\n",
    "            train_points.append((entry['train_step'], entry[train_key]))\n",
    "        if val_key in entry:\n",
    "            val_points.append((entry['train_step'], entry[val_key]))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(name)\n",
    "    x, y = list(zip(*train_points))\n",
    "    plt.plot(x, y, label='train', zorder=1)\n",
    "    x, y = list(zip(*val_points))\n",
    "    plt.scatter(x, y, label='val', zorder=2, marker='+', s=180, c='orange')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренировочный цикл \n",
    "\n",
    "Эпоха -- один проход по датасету.\n",
    "После тренировочной эпохи будем подсчитывать метрики на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, train_loader, val_loader, batch_size=32, epochs=10, device=None):\n",
    "    log = []\n",
    "    train_step = 0\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(output, 1)\n",
    "            acc = (predicted == y).sum().item() / x.size(0)\n",
    "            \n",
    "            log.append(dict(\n",
    "                train_loss=loss.item(),\n",
    "                train_acc=acc,\n",
    "                train_step=train_step,\n",
    "            ))\n",
    "            train_step += 1\n",
    "\n",
    "        # валидационные метрики надо усредних за все валидационные батчи\n",
    "        # hint: для аккумулирования величин удобно взять defaultdict\n",
    "        tmp = defaultdict(list)\n",
    "        model.eval()\n",
    "        for x, y in tqdm(val_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            with torch.no_grad():\n",
    "                # <your code here>\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                acc = (predicted == y).data.numpy()\n",
    "                tmp['acc'].append(acc)\n",
    "                tmp['loss'].append(loss.item())\n",
    "                \n",
    "                \n",
    "        log.append(dict(\n",
    "            val_loss = np.mean(tmp['loss']),  # скаляры\n",
    "            val_acc = np.concatenate(tmp['acc']).mean(),  # массивы, возможно разной длины\n",
    "            train_step=train_step,\n",
    "        ))\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(log, name='loss')\n",
    "        plot_history(log, name='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем заново\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "train_model(net, optimizer, nn.CrossEntropyLoss(), trainloader, testloader, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применим обученную сеть к тренировочным данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# make predictions:\n",
    "outputs = net(images)\n",
    "_, predictions = outputs.topk(1, dim=-1)\n",
    "predictions = predictions.cpu().numpy().flatten()\n",
    "predicted_classes = [classes[i] for i in predictions[:4]]\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images[:4, ...]))\n",
    "\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "print('Predicted: ', ' '.join(predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
